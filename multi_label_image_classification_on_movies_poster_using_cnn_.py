# -*- coding: utf-8 -*-
"""multi label image classification on movies poster using CNN .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WwR7hUTreC7rJcqSroxDxc0olx-F8rNf
"""

!pip uninstall tensorflow-gpu==2.0.0-rc0

import tensorflow as tf 
from tensorflow.keras import Sequential
from  tensorflow.keras.layers import Flatten , Dense , Dropout ,  BatchNormalization , Conv2D , MaxPool2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing import image

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from tqdm import tqdm

!git clone https://github.com/laxmimerit/Movies-Poster_Dataset.git

data=pd.read_csv('/content/Movies-Poster_Dataset/train.csv')
data.shape
data.head()

img_width=350
img_height=350
X=[]
for i in tqdm(range(data.shape[0])):
  path='/content/Movies-Poster_Dataset/Images/'+data['Id'][i]+'.jpg'
  img =image.load_img(path,target_size=(img_width,img_height, 3))
  img = image.img_to_array(img)
  img=img/255.0
  X.append(img) 
X=np.array(X) # list of images
X.shape

!pip install tensorflow-gpu==2.8.0-rc0

plt.imshow(X[1])

data['Genre'][1]

y=data.drop['Id','Genre',axis=1]
y=y.tp_numpy()
y.shape

x_train , x_test , y_train ,y_test =train_test_split(X,y,random_state=0,test_size=0.25)

X_train[0].shape

"""BUILD CNN """

model=Sequential()  
# creating the first layer (conv)
model.add(Conv2D(16,(3,3)),activation='relu',input_shape = x_train[0].shape)
model.add(BatchNormalization()) # normalizationg values between 0-1
model.add(MaxPool2D(2,2))
model.add(dropout(0.3))  #dropping neurons
# creating the second layer( conv)
model.add(Conv2D(64,(3,3),activation='relu')
model.add(BatchNormalization())
model.add(MaxPool2D(2,2))
model.add(dropout(0.4))
# creating the third layer (conv)
model.add(Conv2D(128,(3,3),activation='relu')
model.add(BatchNormalization())
model.add(MaxPool2D(2,2))
model.add(dropout(0.5))

model.add(Flatten()) # makes matrix one vecto)
#create new layer(dense)
model.add(Dense(128,activation='relu'))
model.add(BatchNormalization())
model.add(dropout(0.5))
#
model.add(Dense(128,activation='relu'))
model.add(BatchNormalization())
model.add(dropout(0.5))
#
model.add(Dense(25,activation='sigmoid'))

model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
history=model.fit(x_train,y_train,epochs=5,validation_data=(x_test,y_test))

def plot_learningcurve(history,epoch):
  # plot training and validation accuracy values 
  epoch_range= range(1,epoch+1)
  plt.plot(epoch_range,history.history['accuracy'])
  plt.plot(epoch_range,history.history['val_accuracy'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train','val'],loc='upper left')
  plt.show()
  # plot training and validation loss values 
  plt.plot(epoch_range,history.history['loss'])
  plt.plot(epoch_range,history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train','val'],loc='upper left')
  plt.show()

plot_learningcurve(history,5)

"""TESTING OF MODEL"""

img =image.load_img(endgame.jpg,target_size=(img_width,img_height, 3))
  img = image.img_to_array(img)
  img=img/255.0
  img.reshape(1,img_height,img_height,3)
  classes=data.columns[2:]
  print(classes)
  y_prob=model.predict(img)
  y_prob